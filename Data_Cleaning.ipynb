{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/anaconda3/envs/myenv/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/myenv/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/myenv/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/myenv/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/myenv/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.1)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install mysql-connector-python\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql as mysql\n",
    "import os\n",
    "import warnings\n",
    "import getpass\n",
    "import re  \n",
    "from textblob import TextBlob\n",
    "\n",
    "import mysql.connector as msql\n",
    "from mysql.connector import Error\n",
    "\n",
    "#Python package that provides interfaces to AWS including Amazon S3\n",
    "import boto3\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to connect to db\n",
    "\n",
    "def connect_to_msql(database=''):\n",
    "    try:\n",
    "        conn = msql.connect(host='localhost', user='root', password=getpass.getpass('Enter password:'), database=f'{database}')\n",
    "        print(\"Connected to MySQL...\")\n",
    "    except Error as e:\n",
    "        print(\"Error while connecting to MySQL\", e)\n",
    "    return conn\n",
    "\n",
    "# Function to find unique array values\n",
    "\n",
    "def unique(array):\n",
    "    x = np.array(array)\n",
    "    print(\"Unique list values: \", np.unique(x))\n",
    "    return np.unique(x)\n",
    "\n",
    "# Functions for sentiment analysis\n",
    "\n",
    "def get_sentiment(comment):\n",
    "    blob = TextBlob(comment)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def get_sentiment_label(score):\n",
    "    if score >= 0:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Data from S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new S3 client object that can be used to access and manage objects stored in Amazon S3 buckets\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws access key:········\n",
      "aws secret access key:········\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    region_name='us-east-1',\n",
    "    aws_access_key_id= getpass.getpass('aws access key:'),\n",
    "    aws_secret_access_key= getpass.getpass('aws secret access key:')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='airbnbseattle', key='calendar.csv')\n",
      "s3.ObjectSummary(bucket_name='airbnbseattle', key='listings.csv')\n",
      "s3.ObjectSummary(bucket_name='airbnbseattle', key='reviews.csv')\n"
     ]
    }
   ],
   "source": [
    "for obj in s3.Bucket('airbnbseattle').objects.all():\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Calendar and Export\n",
    "\n",
    "ETA: 3 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get calendar dataset from airbnbseattle bucket\n",
    "cal_object = s3.Bucket('airbnbseattle').Object('calendar.csv').get()\n",
    "calendar = pd.read_csv(cal_object[\"Body\"])\n",
    "\n",
    "# step 1: remove dollar sign and convert to float\n",
    "calendar['price'] = calendar['price'].str.replace('$', '').str.replace(',','').astype(float)\n",
    "\n",
    "# step 2: export csv\n",
    "data = calendar.to_csv('./Clean/calendar.csv')\n",
    "\n",
    "# step 3: Upload calendar.csv into the S3 bucket\n",
    "bucket = s3.Bucket('airbnbseattleclean')\n",
    "bucket.upload_file('./Clean/calendar.csv', 'calendar.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Reviews and Export\n",
    "\n",
    "ETA: 30 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reviews dataset from airbnbseattle bucket\n",
    "rev_object = s3.Bucket('airbnbseattle').Object('reviews.csv').get()\n",
    "reviews = pd.read_csv(rev_object[\"Body\"])\n",
    "reviews = reviews.replace(np.nan, None)\n",
    "\n",
    "# step 1: replace None values with empty string\n",
    "\n",
    "reviews['comments'] = reviews['comments'].replace([None], \"\")\n",
    "\n",
    "# step 2: create new sentiment columns\n",
    "\n",
    "reviews[\"sentiment\"] = reviews[\"comments\"].apply(get_sentiment)\n",
    "reviews[\"sentiment_label\"] = reviews[\"sentiment\"].apply(get_sentiment_label)\n",
    "\n",
    "# step 3: export csv\n",
    "reviews.to_csv('./Clean/reviews.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# step 3: Upload reviews.csv into the S3 bucket\n",
    "bucket = s3.Bucket('airbnbseattleclean')\n",
    "bucket.upload_file('./Clean/reviews.csv', 'reviews.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Listings and Export\n",
    "\n",
    "ETA: 5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get listings dataset from airbnbseattle bucket\n",
    "list_object = s3.Bucket('airbnbseattle').Object('listings.csv').get()\n",
    "listings = pd.read_csv(list_object[\"Body\"])\n",
    "listings = listings.replace(np.nan, None)\n",
    "\n",
    "# step 1: remove dollar sign and convert to float for \n",
    "#   price, weekly_price, security_deposit, cleaning_fee, and extra_people\n",
    "\n",
    "listings['price'] = listings['price'].str.replace('$', '').str.replace(',','').astype(float)\n",
    "listings['weekly_price'] = listings['weekly_price'].str.replace('$', '').str.replace(',','').astype(float)\n",
    "listings['security_deposit'] = listings['security_deposit'].str.replace('$', '').str.replace(',','').astype(float)\n",
    "listings['cleaning_fee'] = listings['cleaning_fee'].str.replace('$', '').str.replace(',','').astype(float)\n",
    "listings['extra_people'] = listings['extra_people'].str.replace('$', '').str.replace(',','').astype(float)\n",
    "\n",
    "# step 2: remove percent sign and convert to float for \n",
    "#   host_response_rate and host_acceptance_rate\n",
    "\n",
    "listings['host_response_rate'] = listings['host_response_rate'].str.replace('%', '').astype(float)\n",
    "listings['host_acceptance_rate'] = listings['host_acceptance_rate'].str.replace('%', '').astype(float)\n",
    "\n",
    "# step 3: convert t and f strings to 1 and 0 for boolean cols\n",
    "\n",
    "bool_cols = [\n",
    "    'host_is_superhost',\n",
    "    'host_has_profile_pic',\n",
    "    'host_identity_verified',\n",
    "    'is_location_exact',\n",
    "    'has_availability',\n",
    "    'requires_license',\n",
    "    'instant_bookable',\n",
    "    'require_guest_profile_picture',\n",
    "    'require_guest_phone_verification'\n",
    "]\n",
    "\n",
    "for cols in bool_cols:\n",
    "    listings[cols] = listings[cols].replace({ 't': 1, 'f': 0 })\n",
    "\n",
    "# step 4: replace None values with empty string\n",
    "\n",
    "listings['summary'] = listings['summary'].replace([None], \"\")\n",
    "listings['space'] = listings['space'].replace([None], \"\")\n",
    "listings['description'] = listings['description'].replace([None], \"\")\n",
    "\n",
    "# step 5: create new sentiment columns\n",
    "\n",
    "listings[\"summary_sentiment\"] = listings[\"summary\"].apply(get_sentiment)\n",
    "listings[\"space_sentiment\"] = listings[\"space\"].apply(get_sentiment)\n",
    "listings[\"description_sentiment\"] = listings[\"description\"].apply(get_sentiment)\n",
    "\n",
    "# step 6: export csv\n",
    "\n",
    "listings.to_csv('./Clean/listings.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# step 7: Upload listings.csv into the S3 bucket\n",
    "bucket = s3.Bucket('airbnbseattleclean')\n",
    "bucket.upload_file('./Clean/listings.csv', 'listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b67baf7d77b2e4322c694a7cdbefbe104fc7a417c712774226af2226d547f1c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
